{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GAN_MNIST.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "dEweWs8RzfDE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "173e6df7-e90c-4b93-9a46-24c0f858d38b"
      },
      "source": [
        "# Loading the libraries\n",
        "from numpy import expand_dims\n",
        "from numpy import zeros\n",
        "from numpy import ones\n",
        "from numpy import vstack\n",
        "from numpy.random import randn\n",
        "from numpy.random import randint\n",
        "from keras.datasets.mnist import load_data\n",
        "from keras.optimizers import Adam\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Reshape\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import Conv2DTranspose\n",
        "from keras.layers import LeakyReLU\n",
        "from keras.layers import Dropout\n",
        "from matplotlib import pyplot\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SS5LMKq0zkrH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define the standalone discriminator model\n",
        "def define_discriminator(in_shape=(28,28,1)):\n",
        "\tmodel = Sequential()\n",
        "\tmodel.add(Conv2D(64, (3,3), strides=(2, 2), padding='same', input_shape=in_shape))\n",
        "\tmodel.add(LeakyReLU(alpha=0.2))\n",
        "\tmodel.add(Dropout(0.4))\n",
        "\tmodel.add(Conv2D(64, (3,3), strides=(2, 2), padding='same'))\n",
        "\tmodel.add(LeakyReLU(alpha=0.2))\n",
        "\tmodel.add(Dropout(0.4))\n",
        "\tmodel.add(Flatten())\n",
        "\tmodel.add(Dense(1, activation='sigmoid'))\n",
        "\t# compile model\n",
        "\topt = Adam(lr=0.0002, beta_1=0.5)\n",
        "\tmodel.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
        "\treturn model\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZDwilinjztfK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define the standalone generator model\n",
        "def define_generator(latent_dim):\n",
        "\tmodel = Sequential()\n",
        "\t# foundation for 7x7 image\n",
        "\tn_nodes = 128 * 7 * 7\n",
        "\tmodel.add(Dense(n_nodes, input_dim=latent_dim))\n",
        "\tmodel.add(LeakyReLU(alpha=0.2))\n",
        "\tmodel.add(Reshape((7, 7, 128)))\n",
        "\t# upsample to 14x14\n",
        "\tmodel.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding='same'))\n",
        "\tmodel.add(LeakyReLU(alpha=0.2))\n",
        "\t# upsample to 28x28\n",
        "\tmodel.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding='same'))\n",
        "\tmodel.add(LeakyReLU(alpha=0.2))\n",
        "\tmodel.add(Conv2D(1, (7,7), activation='sigmoid', padding='same'))\n",
        "\treturn model\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lmRQwjrvz0kI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define the combined generator and discriminator model, for updating the generator\n",
        "def define_gan(g_model, d_model):\n",
        "\t# make weights in the discriminator not trainable\n",
        "\td_model.trainable = False\n",
        "\t# connect them\n",
        "\tmodel = Sequential()\n",
        "\t# add generator\n",
        "\tmodel.add(g_model)\n",
        "\t# add the discriminator\n",
        "\tmodel.add(d_model)\n",
        "\t# compile model\n",
        "\topt = Adam(lr=0.0002, beta_1=0.5)\n",
        "\tmodel.compile(loss='binary_crossentropy', optimizer=opt)\n",
        "\treturn model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Je9_Yn_9z9M5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load and prepare mnist training images\n",
        "def load_real_samples():\n",
        "\t# load mnist dataset\n",
        "\t(trainX, _), (_, _) = load_data()\n",
        "\t# expand to 3d, e.g. add channels dimension\n",
        "\tX = expand_dims(trainX, axis=-1)\n",
        "\t# convert from unsigned ints to floats\n",
        "\tX = X.astype('float32')\n",
        "\t# scale from [0,255] to [0,1]\n",
        "\tX = X / 255.0\n",
        "\treturn X"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lLo9z7bf0EFc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# select real samples\n",
        "def generate_real_samples(dataset, n_samples):\n",
        "\t# choose random instances\n",
        "\tix = randint(0, dataset.shape[0], n_samples)\n",
        "\t# retrieve selected images\n",
        "\tX = dataset[ix]\n",
        "\t# generate 'real' class labels (1)\n",
        "\ty = ones((n_samples, 1))\n",
        "\treturn X, y\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v91jinb20Ob4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# generate points in latent space as input for the generator\n",
        "def generate_latent_points(latent_dim, n_samples):\n",
        "\t# generate points in the latent space\n",
        "\tx_input = randn(latent_dim * n_samples)\n",
        "\t# reshape into a batch of inputs for the network\n",
        "\tx_input = x_input.reshape(n_samples, latent_dim)\n",
        "\treturn x_input\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ghnOYVN0P1i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# use the generator to generate n fake examples, with class labels\n",
        "def generate_fake_samples(g_model, latent_dim, n_samples):\n",
        "\t# generate points in latent space\n",
        "\tx_input = generate_latent_points(latent_dim, n_samples)\n",
        "\t# predict outputs\n",
        "\tX = g_model.predict(x_input)\n",
        "\t# create 'fake' class labels (0)\n",
        "\ty = zeros((n_samples, 1))\n",
        "\treturn X, y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cJ4l1FLw0V6S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create and save a plot of generated images (reversed grayscale)\n",
        "def save_plot(examples, epoch, n=10):\n",
        "\t# plot images\n",
        "\tfor i in range(n * n):\n",
        "\t\t# define subplot\n",
        "\t\tpyplot.subplot(n, n, 1 + i)\n",
        "\t\t# turn off axis\n",
        "\t\tpyplot.axis('off')\n",
        "\t\t# plot raw pixel data\n",
        "\t\tpyplot.imshow(examples[i, :, :, 0], cmap='gray_r')\n",
        "\t# save plot to file\n",
        "\tfilename = 'generated_plot_e%03d.png' % (epoch+1)\n",
        "\tpyplot.savefig(filename)\n",
        "\tpyplot.close()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K5DLltjF0fzd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# evaluate the discriminator, plot generated images, save generator model\n",
        "def summarize_performance(epoch, g_model, d_model, dataset, latent_dim, n_samples=100):\n",
        "\t# prepare real samples\n",
        "\tX_real, y_real = generate_real_samples(dataset, n_samples)\n",
        "\t# evaluate discriminator on real examples\n",
        "\t_, acc_real = d_model.evaluate(X_real, y_real, verbose=0)\n",
        "\t# prepare fake examples\n",
        "\tx_fake, y_fake = generate_fake_samples(g_model, latent_dim, n_samples)\n",
        "\t# evaluate discriminator on fake examples\n",
        "\t_, acc_fake = d_model.evaluate(x_fake, y_fake, verbose=0)\n",
        "\t# summarize discriminator performance\n",
        "\tprint('>Accuracy real: %.0f%%, fake: %.0f%%' % (acc_real*100, acc_fake*100))\n",
        "\t# save plot\n",
        "\tsave_plot(x_fake, epoch)\n",
        "\t# save the generator model tile file\n",
        "\tfilename = 'generator_model_%03d.h5' % (epoch + 1)\n",
        "\tg_model.save(filename)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hTX8peWj0tT-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# train the generator and discriminator\n",
        "def train(g_model, d_model, gan_model, dataset, latent_dim, n_epochs=100, n_batch=256):\n",
        "\tbat_per_epo = int(dataset.shape[0] / n_batch)\n",
        "\thalf_batch = int(n_batch / 2)\n",
        "\t# manually enumerate epochs\n",
        "\tfor i in range(n_epochs):\n",
        "\t\t# enumerate batches over the training set\n",
        "\t\tfor j in range(bat_per_epo):\n",
        "\t\t\t# get randomly selected 'real' samples\n",
        "\t\t\tX_real, y_real = generate_real_samples(dataset, half_batch)\n",
        "\t\t\t# generate 'fake' examples\n",
        "\t\t\tX_fake, y_fake = generate_fake_samples(g_model, latent_dim, half_batch)\n",
        "\t\t\t# create training set for the discriminator\n",
        "\t\t\tX, y = vstack((X_real, X_fake)), vstack((y_real, y_fake))\n",
        "\t\t\t# update discriminator model weights\n",
        "\t\t\td_loss, _ = d_model.train_on_batch(X, y)\n",
        "\t\t\t# prepare points in latent space as input for the generator\n",
        "\t\t\tX_gan = generate_latent_points(latent_dim, n_batch)\n",
        "\t\t\t# create inverted labels for the fake samples\n",
        "\t\t\ty_gan = ones((n_batch, 1))\n",
        "\t\t\t# update the generator via the discriminator's error\n",
        "\t\t\tg_loss = gan_model.train_on_batch(X_gan, y_gan)\n",
        "\t\t\t# summarize loss on this batch\n",
        "\t\t\tprint('>%d, %d/%d, d=%.3f, g=%.3f' % (i+1, j+1, bat_per_epo, d_loss, g_loss))\n",
        "\t\t# evaluate the model performance, sometimes\n",
        "\t\tif (i+1) % 10 == 0:\n",
        "\t\t\tsummarize_performance(i, g_model, d_model, dataset, latent_dim)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C16DF7sW0_1D",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b0767405-0e92-4bec-a117-d45745454c38"
      },
      "source": [
        "# size of the latent space\n",
        "latent_dim = 100\n",
        "# create the discriminator\n",
        "d_model = define_discriminator()\n",
        "# create the generator\n",
        "g_model = define_generator(latent_dim)\n",
        "# create the gan\n",
        "gan_model = define_gan(g_model, d_model)\n",
        "# load image data\n",
        "dataset = load_real_samples()\n",
        "# train model\n",
        "train(g_model, d_model, gan_model, dataset, latent_dim)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/engine/training.py:493: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
            "  'Discrepancy between trainable weights and collected trainable'\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            ">1, 1/234, d=0.709, g=0.684\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/engine/training.py:493: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
            "  'Discrepancy between trainable weights and collected trainable'\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            ">1, 2/234, d=0.702, g=0.711\n",
            ">1, 3/234, d=0.687, g=0.742\n",
            ">1, 4/234, d=0.681, g=0.767\n",
            ">1, 5/234, d=0.665, g=0.797\n",
            ">1, 6/234, d=0.654, g=0.814\n",
            ">1, 7/234, d=0.647, g=0.840\n",
            ">1, 8/234, d=0.640, g=0.854\n",
            ">1, 9/234, d=0.633, g=0.870\n",
            ">1, 10/234, d=0.630, g=0.875\n",
            ">1, 11/234, d=0.629, g=0.865\n",
            ">1, 12/234, d=0.631, g=0.851\n",
            ">1, 13/234, d=0.638, g=0.819\n",
            ">1, 14/234, d=0.643, g=0.788\n",
            ">1, 15/234, d=0.646, g=0.762\n",
            ">1, 16/234, d=0.645, g=0.740\n",
            ">1, 17/234, d=0.645, g=0.725\n",
            ">1, 18/234, d=0.642, g=0.716\n",
            ">1, 19/234, d=0.634, g=0.708\n",
            ">1, 20/234, d=0.625, g=0.704\n",
            ">1, 21/234, d=0.617, g=0.702\n",
            ">1, 22/234, d=0.612, g=0.700\n",
            ">1, 23/234, d=0.604, g=0.700\n",
            ">1, 24/234, d=0.595, g=0.700\n",
            ">1, 25/234, d=0.585, g=0.700\n",
            ">1, 26/234, d=0.570, g=0.701\n",
            ">1, 27/234, d=0.561, g=0.700\n",
            ">1, 28/234, d=0.549, g=0.701\n",
            ">1, 29/234, d=0.539, g=0.702\n",
            ">1, 30/234, d=0.535, g=0.703\n",
            ">1, 31/234, d=0.524, g=0.704\n",
            ">1, 32/234, d=0.513, g=0.705\n",
            ">1, 33/234, d=0.498, g=0.706\n",
            ">1, 34/234, d=0.490, g=0.707\n",
            ">1, 35/234, d=0.491, g=0.708\n",
            ">1, 36/234, d=0.466, g=0.709\n",
            ">1, 37/234, d=0.460, g=0.711\n",
            ">1, 38/234, d=0.459, g=0.712\n",
            ">1, 39/234, d=0.448, g=0.713\n",
            ">1, 40/234, d=0.440, g=0.715\n",
            ">1, 41/234, d=0.431, g=0.717\n",
            ">1, 42/234, d=0.423, g=0.719\n",
            ">1, 43/234, d=0.420, g=0.721\n",
            ">1, 44/234, d=0.411, g=0.723\n",
            ">1, 45/234, d=0.399, g=0.725\n",
            ">1, 46/234, d=0.400, g=0.727\n",
            ">1, 47/234, d=0.392, g=0.731\n",
            ">1, 48/234, d=0.385, g=0.733\n",
            ">1, 49/234, d=0.381, g=0.737\n",
            ">1, 50/234, d=0.375, g=0.740\n",
            ">1, 51/234, d=0.378, g=0.745\n",
            ">1, 52/234, d=0.374, g=0.750\n",
            ">1, 53/234, d=0.367, g=0.754\n",
            ">1, 54/234, d=0.362, g=0.759\n",
            ">1, 55/234, d=0.357, g=0.765\n",
            ">1, 56/234, d=0.355, g=0.770\n",
            ">1, 57/234, d=0.348, g=0.778\n",
            ">1, 58/234, d=0.343, g=0.786\n",
            ">1, 59/234, d=0.334, g=0.795\n",
            ">1, 60/234, d=0.326, g=0.805\n",
            ">1, 61/234, d=0.325, g=0.815\n",
            ">1, 62/234, d=0.326, g=0.826\n",
            ">1, 63/234, d=0.315, g=0.840\n",
            ">1, 64/234, d=0.312, g=0.851\n",
            ">1, 65/234, d=0.304, g=0.864\n",
            ">1, 66/234, d=0.298, g=0.882\n",
            ">1, 67/234, d=0.290, g=0.899\n",
            ">1, 68/234, d=0.284, g=0.919\n",
            ">1, 69/234, d=0.278, g=0.939\n",
            ">1, 70/234, d=0.275, g=0.961\n",
            ">1, 71/234, d=0.265, g=0.987\n",
            ">1, 72/234, d=0.257, g=1.010\n",
            ">1, 73/234, d=0.250, g=1.042\n",
            ">1, 74/234, d=0.239, g=1.071\n",
            ">1, 75/234, d=0.234, g=1.104\n",
            ">1, 76/234, d=0.221, g=1.138\n",
            ">1, 77/234, d=0.215, g=1.177\n",
            ">1, 78/234, d=0.210, g=1.213\n",
            ">1, 79/234, d=0.189, g=1.259\n",
            ">1, 80/234, d=0.189, g=1.302\n",
            ">1, 81/234, d=0.181, g=1.346\n",
            ">1, 82/234, d=0.164, g=1.399\n",
            ">1, 83/234, d=0.163, g=1.450\n",
            ">1, 84/234, d=0.154, g=1.501\n",
            ">1, 85/234, d=0.145, g=1.551\n",
            ">1, 86/234, d=0.140, g=1.614\n",
            ">1, 87/234, d=0.133, g=1.665\n",
            ">1, 88/234, d=0.124, g=1.721\n",
            ">1, 89/234, d=0.116, g=1.783\n",
            ">1, 90/234, d=0.109, g=1.831\n",
            ">1, 91/234, d=0.110, g=1.900\n",
            ">1, 92/234, d=0.101, g=1.960\n",
            ">1, 93/234, d=0.098, g=2.001\n",
            ">1, 94/234, d=0.093, g=2.068\n",
            ">1, 95/234, d=0.086, g=2.118\n",
            ">1, 96/234, d=0.079, g=2.163\n",
            ">1, 97/234, d=0.079, g=2.224\n",
            ">1, 98/234, d=0.074, g=2.276\n",
            ">1, 99/234, d=0.067, g=2.334\n",
            ">1, 100/234, d=0.070, g=2.382\n",
            ">1, 101/234, d=0.065, g=2.421\n",
            ">1, 102/234, d=0.066, g=2.470\n",
            ">1, 103/234, d=0.056, g=2.531\n",
            ">1, 104/234, d=0.063, g=2.556\n",
            ">1, 105/234, d=0.059, g=2.613\n",
            ">1, 106/234, d=0.056, g=2.645\n",
            ">1, 107/234, d=0.051, g=2.686\n",
            ">1, 108/234, d=0.050, g=2.716\n",
            ">1, 109/234, d=0.048, g=2.734\n",
            ">1, 110/234, d=0.045, g=2.695\n",
            ">1, 111/234, d=0.126, g=1.911\n",
            ">1, 112/234, d=2.237, g=0.070\n",
            ">1, 113/234, d=3.111, g=0.030\n",
            ">1, 114/234, d=2.509, g=0.132\n",
            ">1, 115/234, d=1.464, g=0.730\n",
            ">1, 116/234, d=0.635, g=2.031\n",
            ">1, 117/234, d=0.487, g=2.938\n",
            ">1, 118/234, d=0.455, g=3.118\n",
            ">1, 119/234, d=0.363, g=3.060\n",
            ">1, 120/234, d=0.331, g=2.767\n",
            ">1, 121/234, d=0.298, g=2.584\n",
            ">1, 122/234, d=0.288, g=2.430\n",
            ">1, 123/234, d=0.230, g=2.539\n",
            ">1, 124/234, d=0.261, g=2.513\n",
            ">1, 125/234, d=0.228, g=2.556\n",
            ">1, 126/234, d=0.250, g=2.658\n",
            ">1, 127/234, d=0.251, g=2.683\n",
            ">1, 128/234, d=0.271, g=2.404\n",
            ">1, 129/234, d=0.278, g=2.305\n",
            ">1, 130/234, d=0.321, g=2.259\n",
            ">1, 131/234, d=0.371, g=2.277\n",
            ">1, 132/234, d=0.378, g=2.396\n",
            ">1, 133/234, d=0.403, g=2.316\n",
            ">1, 134/234, d=0.389, g=2.137\n",
            ">1, 135/234, d=0.478, g=1.976\n",
            ">1, 136/234, d=0.509, g=1.750\n",
            ">1, 137/234, d=0.488, g=1.687\n",
            ">1, 138/234, d=0.574, g=1.562\n",
            ">1, 139/234, d=0.595, g=1.464\n",
            ">1, 140/234, d=0.618, g=1.411\n",
            ">1, 141/234, d=0.623, g=1.369\n",
            ">1, 142/234, d=0.672, g=1.250\n",
            ">1, 143/234, d=0.697, g=1.109\n",
            ">1, 144/234, d=0.726, g=1.045\n",
            ">1, 145/234, d=0.732, g=0.986\n",
            ">1, 146/234, d=0.768, g=0.999\n",
            ">1, 147/234, d=0.817, g=0.970\n",
            ">1, 148/234, d=0.824, g=1.045\n",
            ">1, 149/234, d=0.811, g=0.995\n",
            ">1, 150/234, d=0.829, g=0.933\n",
            ">1, 151/234, d=0.836, g=0.915\n",
            ">1, 152/234, d=0.862, g=0.924\n",
            ">1, 153/234, d=0.823, g=0.908\n",
            ">1, 154/234, d=0.801, g=0.928\n",
            ">1, 155/234, d=0.812, g=0.903\n",
            ">1, 156/234, d=0.811, g=0.904\n",
            ">1, 157/234, d=0.842, g=0.903\n",
            ">1, 158/234, d=0.810, g=0.910\n",
            ">1, 159/234, d=0.828, g=0.900\n",
            ">1, 160/234, d=0.814, g=0.869\n",
            ">1, 161/234, d=0.753, g=0.947\n",
            ">1, 162/234, d=0.768, g=0.904\n",
            ">1, 163/234, d=0.776, g=0.914\n",
            ">1, 164/234, d=0.774, g=0.895\n",
            ">1, 165/234, d=0.763, g=0.920\n",
            ">1, 166/234, d=0.771, g=0.903\n",
            ">1, 167/234, d=0.742, g=0.913\n",
            ">1, 168/234, d=0.732, g=0.905\n",
            ">1, 169/234, d=0.731, g=0.939\n",
            ">1, 170/234, d=0.707, g=0.886\n",
            ">1, 171/234, d=0.706, g=0.847\n",
            ">1, 172/234, d=0.721, g=0.817\n",
            ">1, 173/234, d=0.712, g=0.815\n",
            ">1, 174/234, d=0.676, g=0.776\n",
            ">1, 175/234, d=0.721, g=0.760\n",
            ">1, 176/234, d=0.696, g=0.727\n",
            ">1, 177/234, d=0.673, g=0.735\n",
            ">1, 178/234, d=0.659, g=0.718\n",
            ">1, 179/234, d=0.663, g=0.713\n",
            ">1, 180/234, d=0.678, g=0.716\n",
            ">1, 181/234, d=0.702, g=0.706\n",
            ">1, 182/234, d=0.665, g=0.750\n",
            ">1, 183/234, d=0.658, g=0.762\n",
            ">1, 184/234, d=0.663, g=0.796\n",
            ">1, 185/234, d=0.651, g=0.842\n",
            ">1, 186/234, d=0.634, g=0.850\n",
            ">1, 187/234, d=0.643, g=0.866\n",
            ">1, 188/234, d=0.660, g=0.875\n",
            ">1, 189/234, d=0.651, g=0.869\n",
            ">1, 190/234, d=0.643, g=0.885\n",
            ">1, 191/234, d=0.634, g=0.831\n",
            ">1, 192/234, d=0.632, g=0.794\n",
            ">1, 193/234, d=0.604, g=0.764\n",
            ">1, 194/234, d=0.640, g=0.746\n",
            ">1, 195/234, d=0.624, g=0.736\n",
            ">1, 196/234, d=0.616, g=0.714\n",
            ">1, 197/234, d=0.620, g=0.691\n",
            ">1, 198/234, d=0.642, g=0.694\n",
            ">1, 199/234, d=0.626, g=0.712\n",
            ">1, 200/234, d=0.660, g=0.759\n",
            ">1, 201/234, d=0.653, g=0.801\n",
            ">1, 202/234, d=0.680, g=0.925\n",
            ">1, 203/234, d=0.684, g=1.092\n",
            ">1, 204/234, d=0.653, g=1.188\n",
            ">1, 205/234, d=0.670, g=1.138\n",
            ">1, 206/234, d=0.724, g=1.011\n",
            ">1, 207/234, d=0.692, g=0.874\n",
            ">1, 208/234, d=0.715, g=0.791\n",
            ">1, 209/234, d=0.692, g=0.731\n",
            ">1, 210/234, d=0.678, g=0.684\n",
            ">1, 211/234, d=0.710, g=0.656\n",
            ">1, 212/234, d=0.728, g=0.647\n",
            ">1, 213/234, d=0.742, g=0.637\n",
            ">1, 214/234, d=0.752, g=0.731\n",
            ">1, 215/234, d=0.703, g=0.813\n",
            ">1, 216/234, d=0.675, g=0.877\n",
            ">1, 217/234, d=0.681, g=0.891\n",
            ">1, 218/234, d=0.664, g=0.900\n",
            ">1, 219/234, d=0.649, g=0.912\n",
            ">1, 220/234, d=0.635, g=0.883\n",
            ">1, 221/234, d=0.623, g=0.868\n",
            ">1, 222/234, d=0.599, g=0.846\n",
            ">1, 223/234, d=0.596, g=0.809\n",
            ">1, 224/234, d=0.609, g=0.857\n",
            ">1, 225/234, d=0.573, g=0.840\n",
            ">1, 226/234, d=0.555, g=0.824\n",
            ">1, 227/234, d=0.574, g=0.841\n",
            ">1, 228/234, d=0.554, g=0.822\n",
            ">1, 229/234, d=0.541, g=0.868\n",
            ">1, 230/234, d=0.555, g=0.859\n",
            ">1, 231/234, d=0.544, g=0.874\n",
            ">1, 232/234, d=0.525, g=0.837\n",
            ">1, 233/234, d=0.523, g=0.833\n",
            ">1, 234/234, d=0.505, g=0.849\n",
            ">2, 1/234, d=0.515, g=0.845\n",
            ">2, 2/234, d=0.543, g=0.864\n",
            ">2, 3/234, d=0.542, g=0.860\n",
            ">2, 4/234, d=0.556, g=0.863\n",
            ">2, 5/234, d=0.581, g=0.849\n",
            ">2, 6/234, d=0.600, g=0.819\n",
            ">2, 7/234, d=0.723, g=0.908\n",
            ">2, 8/234, d=0.677, g=1.019\n",
            ">2, 9/234, d=0.729, g=1.135\n",
            ">2, 10/234, d=0.763, g=1.112\n",
            ">2, 11/234, d=0.790, g=0.886\n",
            ">2, 12/234, d=0.845, g=0.768\n",
            ">2, 13/234, d=0.865, g=0.656\n",
            ">2, 14/234, d=0.891, g=0.595\n",
            ">2, 15/234, d=0.915, g=0.565\n",
            ">2, 16/234, d=0.925, g=0.548\n",
            ">2, 17/234, d=0.904, g=0.561\n",
            ">2, 18/234, d=0.890, g=0.619\n",
            ">2, 19/234, d=0.906, g=0.645\n",
            ">2, 20/234, d=0.895, g=0.700\n",
            ">2, 21/234, d=0.934, g=0.690\n",
            ">2, 22/234, d=0.938, g=0.707\n",
            ">2, 23/234, d=0.917, g=0.743\n",
            ">2, 24/234, d=0.910, g=0.690\n",
            ">2, 25/234, d=0.926, g=0.680\n",
            ">2, 26/234, d=0.922, g=0.637\n",
            ">2, 27/234, d=0.891, g=0.593\n",
            ">2, 28/234, d=0.893, g=0.568\n",
            ">2, 29/234, d=0.885, g=0.553\n",
            ">2, 30/234, d=0.863, g=0.538\n",
            ">2, 31/234, d=0.857, g=0.537\n",
            ">2, 32/234, d=0.822, g=0.557\n",
            ">2, 33/234, d=0.800, g=0.572\n",
            ">2, 34/234, d=0.759, g=0.595\n",
            ">2, 35/234, d=0.748, g=0.627\n",
            ">2, 36/234, d=0.715, g=0.657\n",
            ">2, 37/234, d=0.677, g=0.690\n",
            ">2, 38/234, d=0.652, g=0.706\n",
            ">2, 39/234, d=0.642, g=0.722\n",
            ">2, 40/234, d=0.628, g=0.749\n",
            ">2, 41/234, d=0.591, g=0.770\n",
            ">2, 42/234, d=0.571, g=0.794\n",
            ">2, 43/234, d=0.562, g=0.814\n",
            ">2, 44/234, d=0.552, g=0.822\n",
            ">2, 45/234, d=0.530, g=0.842\n",
            ">2, 46/234, d=0.526, g=0.851\n",
            ">2, 47/234, d=0.541, g=0.876\n",
            ">2, 48/234, d=0.526, g=0.894\n",
            ">2, 49/234, d=0.539, g=0.929\n",
            ">2, 50/234, d=0.526, g=0.932\n",
            ">2, 51/234, d=0.511, g=0.952\n",
            ">2, 52/234, d=0.539, g=0.941\n",
            ">2, 53/234, d=0.537, g=0.916\n",
            ">2, 54/234, d=0.522, g=0.912\n",
            ">2, 55/234, d=0.514, g=0.886\n",
            ">2, 56/234, d=0.523, g=0.867\n",
            ">2, 57/234, d=0.542, g=0.858\n",
            ">2, 58/234, d=0.536, g=0.857\n",
            ">2, 59/234, d=0.546, g=0.861\n",
            ">2, 60/234, d=0.551, g=0.826\n",
            ">2, 61/234, d=0.579, g=0.866\n",
            ">2, 62/234, d=0.609, g=0.873\n",
            ">2, 63/234, d=0.636, g=0.922\n",
            ">2, 64/234, d=0.651, g=0.999\n",
            ">2, 65/234, d=0.667, g=1.027\n",
            ">2, 66/234, d=0.690, g=1.037\n",
            ">2, 67/234, d=0.693, g=1.036\n",
            ">2, 68/234, d=0.724, g=0.932\n",
            ">2, 69/234, d=0.731, g=0.816\n",
            ">2, 70/234, d=0.729, g=0.760\n",
            ">2, 71/234, d=0.767, g=0.665\n",
            ">2, 72/234, d=0.769, g=0.665\n",
            ">2, 73/234, d=0.795, g=0.634\n",
            ">2, 74/234, d=0.809, g=0.621\n",
            ">2, 75/234, d=0.834, g=0.608\n",
            ">2, 76/234, d=0.842, g=0.592\n",
            ">2, 77/234, d=0.862, g=0.619\n",
            ">2, 78/234, d=0.895, g=0.605\n",
            ">2, 79/234, d=0.851, g=0.612\n",
            ">2, 80/234, d=0.908, g=0.604\n",
            ">2, 81/234, d=0.913, g=0.592\n",
            ">2, 82/234, d=0.930, g=0.576\n",
            ">2, 83/234, d=0.904, g=0.558\n",
            ">2, 84/234, d=0.892, g=0.576\n",
            ">2, 85/234, d=0.864, g=0.590\n",
            ">2, 86/234, d=0.868, g=0.606\n",
            ">2, 87/234, d=0.864, g=0.611\n",
            ">2, 88/234, d=0.842, g=0.643\n",
            ">2, 89/234, d=0.819, g=0.669\n",
            ">2, 90/234, d=0.779, g=0.680\n",
            ">2, 91/234, d=0.775, g=0.680\n",
            ">2, 92/234, d=0.757, g=0.691\n",
            ">2, 93/234, d=0.720, g=0.704\n",
            ">2, 94/234, d=0.724, g=0.702\n",
            ">2, 95/234, d=0.688, g=0.719\n",
            ">2, 96/234, d=0.691, g=0.725\n",
            ">2, 97/234, d=0.671, g=0.716\n",
            ">2, 98/234, d=0.665, g=0.726\n",
            ">2, 99/234, d=0.646, g=0.733\n",
            ">2, 100/234, d=0.648, g=0.753\n",
            ">2, 101/234, d=0.612, g=0.760\n",
            ">2, 102/234, d=0.599, g=0.777\n",
            ">2, 103/234, d=0.591, g=0.782\n",
            ">2, 104/234, d=0.555, g=0.807\n",
            ">2, 105/234, d=0.564, g=0.837\n",
            ">2, 106/234, d=0.546, g=0.846\n",
            ">2, 107/234, d=0.523, g=0.861\n",
            ">2, 108/234, d=0.529, g=0.884\n",
            ">2, 109/234, d=0.513, g=0.897\n",
            ">2, 110/234, d=0.512, g=0.899\n",
            ">2, 111/234, d=0.490, g=0.913\n",
            ">2, 112/234, d=0.484, g=0.919\n",
            ">2, 113/234, d=0.476, g=0.933\n",
            ">2, 114/234, d=0.486, g=0.962\n",
            ">2, 115/234, d=0.471, g=0.943\n",
            ">2, 116/234, d=0.474, g=0.975\n",
            ">2, 117/234, d=0.489, g=0.913\n",
            ">2, 118/234, d=0.551, g=0.887\n",
            ">2, 119/234, d=0.655, g=0.855\n",
            ">2, 120/234, d=0.706, g=1.047\n",
            ">2, 121/234, d=0.680, g=1.384\n",
            ">2, 122/234, d=0.642, g=1.471\n",
            ">2, 123/234, d=0.661, g=1.395\n",
            ">2, 124/234, d=0.674, g=1.213\n",
            ">2, 125/234, d=0.697, g=1.073\n",
            ">2, 126/234, d=0.678, g=0.932\n",
            ">2, 127/234, d=0.706, g=0.840\n",
            ">2, 128/234, d=0.711, g=0.760\n",
            ">2, 129/234, d=0.728, g=0.725\n",
            ">2, 130/234, d=0.737, g=0.695\n",
            ">2, 131/234, d=0.745, g=0.670\n",
            ">2, 132/234, d=0.751, g=0.651\n",
            ">2, 133/234, d=0.794, g=0.635\n",
            ">2, 134/234, d=0.773, g=0.631\n",
            ">2, 135/234, d=0.770, g=0.625\n",
            ">2, 136/234, d=0.780, g=0.621\n",
            ">2, 137/234, d=0.801, g=0.636\n",
            ">2, 138/234, d=0.782, g=0.628\n",
            ">2, 139/234, d=0.800, g=0.640\n",
            ">2, 140/234, d=0.817, g=0.634\n",
            ">2, 141/234, d=0.783, g=0.633\n",
            ">2, 142/234, d=0.800, g=0.656\n",
            ">2, 143/234, d=0.798, g=0.670\n",
            ">2, 144/234, d=0.775, g=0.675\n",
            ">2, 145/234, d=0.764, g=0.694\n",
            ">2, 146/234, d=0.740, g=0.713\n",
            ">2, 147/234, d=0.741, g=0.737\n",
            ">2, 148/234, d=0.715, g=0.742\n",
            ">2, 149/234, d=0.697, g=0.770\n",
            ">2, 150/234, d=0.694, g=0.788\n",
            ">2, 151/234, d=0.679, g=0.798\n",
            ">2, 152/234, d=0.659, g=0.797\n",
            ">2, 153/234, d=0.630, g=0.816\n",
            ">2, 154/234, d=0.618, g=0.824\n",
            ">2, 155/234, d=0.608, g=0.831\n",
            ">2, 156/234, d=0.589, g=0.844\n",
            ">2, 157/234, d=0.595, g=0.849\n",
            ">2, 158/234, d=0.602, g=0.843\n",
            ">2, 159/234, d=0.568, g=0.838\n",
            ">2, 160/234, d=0.572, g=0.826\n",
            ">2, 161/234, d=0.552, g=0.843\n",
            ">2, 162/234, d=0.569, g=0.814\n",
            ">2, 163/234, d=0.581, g=0.842\n",
            ">2, 164/234, d=0.587, g=0.841\n",
            ">2, 165/234, d=0.558, g=0.836\n",
            ">2, 166/234, d=0.587, g=0.850\n",
            ">2, 167/234, d=0.596, g=0.835\n",
            ">2, 168/234, d=0.603, g=0.843\n",
            ">2, 169/234, d=0.623, g=0.845\n",
            ">2, 170/234, d=0.609, g=0.850\n",
            ">2, 171/234, d=0.616, g=0.848\n",
            ">2, 172/234, d=0.625, g=0.866\n",
            ">2, 173/234, d=0.615, g=0.853\n",
            ">2, 174/234, d=0.648, g=0.841\n",
            ">2, 175/234, d=0.620, g=0.827\n",
            ">2, 176/234, d=0.624, g=0.797\n",
            ">2, 177/234, d=0.651, g=0.773\n",
            ">2, 178/234, d=0.645, g=0.761\n",
            ">2, 179/234, d=0.661, g=0.733\n",
            ">2, 180/234, d=0.677, g=0.736\n",
            ">2, 181/234, d=0.671, g=0.727\n",
            ">2, 182/234, d=0.665, g=0.744\n",
            ">2, 183/234, d=0.670, g=0.747\n",
            ">2, 184/234, d=0.674, g=0.741\n",
            ">2, 185/234, d=0.680, g=0.764\n",
            ">2, 186/234, d=0.697, g=0.764\n",
            ">2, 187/234, d=0.674, g=0.758\n",
            ">2, 188/234, d=0.673, g=0.756\n",
            ">2, 189/234, d=0.699, g=0.738\n",
            ">2, 190/234, d=0.691, g=0.713\n",
            ">2, 191/234, d=0.696, g=0.738\n",
            ">2, 192/234, d=0.693, g=0.712\n",
            ">2, 193/234, d=0.698, g=0.705\n",
            ">2, 194/234, d=0.695, g=0.703\n",
            ">2, 195/234, d=0.687, g=0.719\n",
            ">2, 196/234, d=0.715, g=0.681\n",
            ">2, 197/234, d=0.697, g=0.685\n",
            ">2, 198/234, d=0.708, g=0.683\n",
            ">2, 199/234, d=0.714, g=0.702\n",
            ">2, 200/234, d=0.707, g=0.705\n",
            ">2, 201/234, d=0.716, g=0.697\n",
            ">2, 202/234, d=0.717, g=0.710\n",
            ">2, 203/234, d=0.708, g=0.688\n",
            ">2, 204/234, d=0.699, g=0.691\n",
            ">2, 205/234, d=0.716, g=0.700\n",
            ">2, 206/234, d=0.720, g=0.713\n",
            ">2, 207/234, d=0.697, g=0.695\n",
            ">2, 208/234, d=0.707, g=0.698\n",
            ">2, 209/234, d=0.711, g=0.673\n",
            ">2, 210/234, d=0.706, g=0.706\n",
            ">2, 211/234, d=0.716, g=0.705\n",
            ">2, 212/234, d=0.702, g=0.679\n",
            ">2, 213/234, d=0.708, g=0.687\n",
            ">2, 214/234, d=0.705, g=0.701\n",
            ">2, 215/234, d=0.691, g=0.707\n",
            ">2, 216/234, d=0.694, g=0.711\n",
            ">2, 217/234, d=0.706, g=0.704\n",
            ">2, 218/234, d=0.706, g=0.691\n",
            ">2, 219/234, d=0.698, g=0.689\n",
            ">2, 220/234, d=0.703, g=0.692\n",
            ">2, 221/234, d=0.697, g=0.699\n",
            ">2, 222/234, d=0.689, g=0.693\n",
            ">2, 223/234, d=0.690, g=0.707\n",
            ">2, 224/234, d=0.704, g=0.699\n",
            ">2, 225/234, d=0.716, g=0.695\n",
            ">2, 226/234, d=0.706, g=0.699\n",
            ">2, 227/234, d=0.703, g=0.688\n",
            ">2, 228/234, d=0.707, g=0.712\n",
            ">2, 229/234, d=0.703, g=0.700\n",
            ">2, 230/234, d=0.689, g=0.720\n",
            ">2, 231/234, d=0.690, g=0.724\n",
            ">2, 232/234, d=0.685, g=0.723\n",
            ">2, 233/234, d=0.692, g=0.712\n",
            ">2, 234/234, d=0.704, g=0.715\n",
            ">3, 1/234, d=0.687, g=0.714\n",
            ">3, 2/234, d=0.691, g=0.698\n",
            ">3, 3/234, d=0.695, g=0.707\n",
            ">3, 4/234, d=0.696, g=0.723\n",
            ">3, 5/234, d=0.692, g=0.716\n",
            ">3, 6/234, d=0.691, g=0.703\n",
            ">3, 7/234, d=0.699, g=0.711\n",
            ">3, 8/234, d=0.702, g=0.704\n",
            ">3, 9/234, d=0.689, g=0.701\n",
            ">3, 10/234, d=0.693, g=0.698\n",
            ">3, 11/234, d=0.707, g=0.714\n",
            ">3, 12/234, d=0.702, g=0.728\n",
            ">3, 13/234, d=0.696, g=0.710\n",
            ">3, 14/234, d=0.707, g=0.732\n",
            ">3, 15/234, d=0.696, g=0.724\n",
            ">3, 16/234, d=0.698, g=0.707\n",
            ">3, 17/234, d=0.714, g=0.708\n",
            ">3, 18/234, d=0.705, g=0.715\n",
            ">3, 19/234, d=0.693, g=0.723\n",
            ">3, 20/234, d=0.701, g=0.726\n",
            ">3, 21/234, d=0.692, g=0.714\n",
            ">3, 22/234, d=0.699, g=0.703\n",
            ">3, 23/234, d=0.697, g=0.711\n",
            ">3, 24/234, d=0.711, g=0.710\n",
            ">3, 25/234, d=0.692, g=0.709\n",
            ">3, 26/234, d=0.700, g=0.740\n",
            ">3, 27/234, d=0.696, g=0.739\n",
            ">3, 28/234, d=0.693, g=0.739\n",
            ">3, 29/234, d=0.685, g=0.738\n",
            ">3, 30/234, d=0.706, g=0.748\n",
            ">3, 31/234, d=0.713, g=0.733\n",
            ">3, 32/234, d=0.689, g=0.724\n",
            ">3, 33/234, d=0.681, g=0.748\n",
            ">3, 34/234, d=0.690, g=0.738\n",
            ">3, 35/234, d=0.679, g=0.738\n",
            ">3, 36/234, d=0.690, g=0.725\n",
            ">3, 37/234, d=0.686, g=0.715\n",
            ">3, 38/234, d=0.676, g=0.722\n",
            ">3, 39/234, d=0.675, g=0.717\n",
            ">3, 40/234, d=0.704, g=0.726\n",
            ">3, 41/234, d=0.673, g=0.730\n",
            ">3, 42/234, d=0.669, g=0.728\n",
            ">3, 43/234, d=0.671, g=0.759\n",
            ">3, 44/234, d=0.663, g=0.766\n",
            ">3, 45/234, d=0.663, g=0.784\n",
            ">3, 46/234, d=0.667, g=0.794\n",
            ">3, 47/234, d=0.666, g=0.782\n",
            ">3, 48/234, d=0.664, g=0.786\n",
            ">3, 49/234, d=0.668, g=0.767\n",
            ">3, 50/234, d=0.660, g=0.757\n",
            ">3, 51/234, d=0.660, g=0.751\n",
            ">3, 52/234, d=0.671, g=0.748\n",
            ">3, 53/234, d=0.668, g=0.763\n",
            ">3, 54/234, d=0.670, g=0.751\n",
            ">3, 55/234, d=0.675, g=0.762\n",
            ">3, 56/234, d=0.655, g=0.764\n",
            ">3, 57/234, d=0.664, g=0.763\n",
            ">3, 58/234, d=0.644, g=0.769\n",
            ">3, 59/234, d=0.668, g=0.749\n",
            ">3, 60/234, d=0.655, g=0.719\n",
            ">3, 61/234, d=0.655, g=0.759\n",
            ">3, 62/234, d=0.665, g=0.754\n",
            ">3, 63/234, d=0.661, g=0.744\n",
            ">3, 64/234, d=0.653, g=0.776\n",
            ">3, 65/234, d=0.661, g=0.791\n",
            ">3, 66/234, d=0.644, g=0.805\n",
            ">3, 67/234, d=0.651, g=0.806\n",
            ">3, 68/234, d=0.666, g=0.805\n",
            ">3, 69/234, d=0.669, g=0.769\n",
            ">3, 70/234, d=0.677, g=0.764\n",
            ">3, 71/234, d=0.670, g=0.736\n",
            ">3, 72/234, d=0.650, g=0.735\n",
            ">3, 73/234, d=0.659, g=0.724\n",
            ">3, 74/234, d=0.677, g=0.730\n",
            ">3, 75/234, d=0.653, g=0.710\n",
            ">3, 76/234, d=0.668, g=0.725\n",
            ">3, 77/234, d=0.659, g=0.731\n",
            ">3, 78/234, d=0.663, g=0.739\n",
            ">3, 79/234, d=0.671, g=0.746\n",
            ">3, 80/234, d=0.675, g=0.728\n",
            ">3, 81/234, d=0.678, g=0.740\n",
            ">3, 82/234, d=0.664, g=0.736\n",
            ">3, 83/234, d=0.667, g=0.735\n",
            ">3, 84/234, d=0.676, g=0.731\n",
            ">3, 85/234, d=0.671, g=0.731\n",
            ">3, 86/234, d=0.683, g=0.716\n",
            ">3, 87/234, d=0.678, g=0.728\n",
            ">3, 88/234, d=0.690, g=0.721\n",
            ">3, 89/234, d=0.689, g=0.735\n",
            ">3, 90/234, d=0.678, g=0.713\n",
            ">3, 91/234, d=0.690, g=0.712\n",
            ">3, 92/234, d=0.671, g=0.708\n",
            ">3, 93/234, d=0.696, g=0.697\n",
            ">3, 94/234, d=0.677, g=0.722\n",
            ">3, 95/234, d=0.692, g=0.707\n",
            ">3, 96/234, d=0.690, g=0.701\n",
            ">3, 97/234, d=0.682, g=0.713\n",
            ">3, 98/234, d=0.704, g=0.709\n",
            ">3, 99/234, d=0.702, g=0.713\n",
            ">3, 100/234, d=0.698, g=0.716\n",
            ">3, 101/234, d=0.704, g=0.708\n",
            ">3, 102/234, d=0.694, g=0.690\n",
            ">3, 103/234, d=0.692, g=0.695\n",
            ">3, 104/234, d=0.684, g=0.700\n",
            ">3, 105/234, d=0.699, g=0.689\n",
            ">3, 106/234, d=0.696, g=0.708\n",
            ">3, 107/234, d=0.709, g=0.701\n",
            ">3, 108/234, d=0.681, g=0.681\n",
            ">3, 109/234, d=0.702, g=0.716\n",
            ">3, 110/234, d=0.721, g=0.707\n",
            ">3, 111/234, d=0.701, g=0.725\n",
            ">3, 112/234, d=0.696, g=0.720\n",
            ">3, 113/234, d=0.703, g=0.696\n",
            ">3, 114/234, d=0.704, g=0.692\n",
            ">3, 115/234, d=0.703, g=0.706\n",
            ">3, 116/234, d=0.714, g=0.688\n",
            ">3, 117/234, d=0.703, g=0.699\n",
            ">3, 118/234, d=0.703, g=0.705\n",
            ">3, 119/234, d=0.698, g=0.711\n",
            ">3, 120/234, d=0.706, g=0.696\n",
            ">3, 121/234, d=0.708, g=0.692\n",
            ">3, 122/234, d=0.699, g=0.689\n",
            ">3, 123/234, d=0.702, g=0.706\n",
            ">3, 124/234, d=0.716, g=0.709\n",
            ">3, 125/234, d=0.712, g=0.703\n",
            ">3, 126/234, d=0.707, g=0.707\n",
            ">3, 127/234, d=0.699, g=0.699\n",
            ">3, 128/234, d=0.695, g=0.712\n",
            ">3, 129/234, d=0.694, g=0.722\n",
            ">3, 130/234, d=0.709, g=0.714\n",
            ">3, 131/234, d=0.709, g=0.719\n",
            ">3, 132/234, d=0.702, g=0.722\n",
            ">3, 133/234, d=0.709, g=0.696\n",
            ">3, 134/234, d=0.700, g=0.715\n",
            ">3, 135/234, d=0.707, g=0.702\n",
            ">3, 136/234, d=0.716, g=0.715\n",
            ">3, 137/234, d=0.715, g=0.725\n",
            ">3, 138/234, d=0.701, g=0.726\n",
            ">3, 139/234, d=0.698, g=0.709\n",
            ">3, 140/234, d=0.683, g=0.711\n",
            ">3, 141/234, d=0.692, g=0.698\n",
            ">3, 142/234, d=0.697, g=0.716\n",
            ">3, 143/234, d=0.688, g=0.713\n",
            ">3, 144/234, d=0.684, g=0.726\n",
            ">3, 145/234, d=0.700, g=0.710\n",
            ">3, 146/234, d=0.695, g=0.742\n",
            ">3, 147/234, d=0.692, g=0.734\n",
            ">3, 148/234, d=0.678, g=0.739\n",
            ">3, 149/234, d=0.683, g=0.747\n",
            ">3, 150/234, d=0.698, g=0.743\n",
            ">3, 151/234, d=0.681, g=0.747\n",
            ">3, 152/234, d=0.681, g=0.739\n",
            ">3, 153/234, d=0.685, g=0.728\n",
            ">3, 154/234, d=0.688, g=0.718\n",
            ">3, 155/234, d=0.682, g=0.734\n",
            ">3, 156/234, d=0.690, g=0.731\n",
            ">3, 157/234, d=0.691, g=0.724\n",
            ">3, 158/234, d=0.676, g=0.738\n",
            ">3, 159/234, d=0.676, g=0.753\n",
            ">3, 160/234, d=0.688, g=0.737\n",
            ">3, 161/234, d=0.683, g=0.733\n",
            ">3, 162/234, d=0.669, g=0.736\n",
            ">3, 163/234, d=0.665, g=0.730\n",
            ">3, 164/234, d=0.673, g=0.743\n",
            ">3, 165/234, d=0.668, g=0.749\n",
            ">3, 166/234, d=0.678, g=0.754\n",
            ">3, 167/234, d=0.659, g=0.749\n",
            ">3, 168/234, d=0.660, g=0.750\n",
            ">3, 169/234, d=0.654, g=0.744\n",
            ">3, 170/234, d=0.650, g=0.753\n",
            ">3, 171/234, d=0.649, g=0.757\n",
            ">3, 172/234, d=0.651, g=0.759\n",
            ">3, 173/234, d=0.652, g=0.750\n",
            ">3, 174/234, d=0.651, g=0.739\n",
            ">3, 175/234, d=0.639, g=0.762\n",
            ">3, 176/234, d=0.644, g=0.752\n",
            ">3, 177/234, d=0.651, g=0.773\n",
            ">3, 178/234, d=0.645, g=0.777\n",
            ">3, 179/234, d=0.652, g=0.774\n",
            ">3, 180/234, d=0.664, g=0.768\n",
            ">3, 181/234, d=0.656, g=0.756\n",
            ">3, 182/234, d=0.655, g=0.750\n",
            ">3, 183/234, d=0.659, g=0.721\n",
            ">3, 184/234, d=0.661, g=0.721\n",
            ">3, 185/234, d=0.669, g=0.712\n",
            ">3, 186/234, d=0.675, g=0.698\n",
            ">3, 187/234, d=0.687, g=0.722\n",
            ">3, 188/234, d=0.681, g=0.736\n",
            ">3, 189/234, d=0.674, g=0.725\n",
            ">3, 190/234, d=0.702, g=0.733\n",
            ">3, 191/234, d=0.699, g=0.729\n",
            ">3, 192/234, d=0.690, g=0.706\n",
            ">3, 193/234, d=0.684, g=0.716\n",
            ">3, 194/234, d=0.702, g=0.695\n",
            ">3, 195/234, d=0.699, g=0.680\n",
            ">3, 196/234, d=0.709, g=0.675\n",
            ">3, 197/234, d=0.726, g=0.675\n",
            ">3, 198/234, d=0.723, g=0.684\n",
            ">3, 199/234, d=0.716, g=0.690\n",
            ">3, 200/234, d=0.728, g=0.684\n",
            ">3, 201/234, d=0.725, g=0.687\n",
            ">3, 202/234, d=0.728, g=0.687\n",
            ">3, 203/234, d=0.739, g=0.684\n",
            ">3, 204/234, d=0.735, g=0.681\n",
            ">3, 205/234, d=0.740, g=0.683\n",
            ">3, 206/234, d=0.733, g=0.666\n",
            ">3, 207/234, d=0.722, g=0.682\n",
            ">3, 208/234, d=0.718, g=0.682\n",
            ">3, 209/234, d=0.716, g=0.691\n",
            ">3, 210/234, d=0.719, g=0.705\n",
            ">3, 211/234, d=0.696, g=0.751\n",
            ">3, 212/234, d=0.696, g=0.742\n",
            ">3, 213/234, d=0.687, g=0.747\n",
            ">3, 214/234, d=0.668, g=0.748\n",
            ">3, 215/234, d=0.662, g=0.758\n",
            ">3, 216/234, d=0.665, g=0.761\n",
            ">3, 217/234, d=0.669, g=0.784\n",
            ">3, 218/234, d=0.635, g=0.783\n",
            ">3, 219/234, d=0.667, g=0.796\n",
            ">3, 220/234, d=0.640, g=0.788\n",
            ">3, 221/234, d=0.635, g=0.777\n",
            ">3, 222/234, d=0.642, g=0.774\n",
            ">3, 223/234, d=0.637, g=0.771\n",
            ">3, 224/234, d=0.640, g=0.773\n",
            ">3, 225/234, d=0.655, g=0.775\n",
            ">3, 226/234, d=0.648, g=0.766\n",
            ">3, 227/234, d=0.663, g=0.752\n",
            ">3, 228/234, d=0.656, g=0.742\n",
            ">3, 229/234, d=0.671, g=0.752\n",
            ">3, 230/234, d=0.668, g=0.740\n",
            ">3, 231/234, d=0.686, g=0.718\n",
            ">3, 232/234, d=0.701, g=0.698\n",
            ">3, 233/234, d=0.693, g=0.693\n",
            ">3, 234/234, d=0.679, g=0.698\n",
            ">4, 1/234, d=0.707, g=0.691\n",
            ">4, 2/234, d=0.721, g=0.691\n",
            ">4, 3/234, d=0.709, g=0.690\n",
            ">4, 4/234, d=0.708, g=0.686\n",
            ">4, 5/234, d=0.719, g=0.695\n",
            ">4, 6/234, d=0.699, g=0.695\n",
            ">4, 7/234, d=0.710, g=0.676\n",
            ">4, 8/234, d=0.730, g=0.672\n",
            ">4, 9/234, d=0.744, g=0.674\n",
            ">4, 10/234, d=0.725, g=0.659\n",
            ">4, 11/234, d=0.728, g=0.651\n",
            ">4, 12/234, d=0.744, g=0.652\n",
            ">4, 13/234, d=0.754, g=0.681\n",
            ">4, 14/234, d=0.749, g=0.672\n",
            ">4, 15/234, d=0.733, g=0.683\n",
            ">4, 16/234, d=0.746, g=0.687\n",
            ">4, 17/234, d=0.739, g=0.682\n",
            ">4, 18/234, d=0.751, g=0.680\n",
            ">4, 19/234, d=0.748, g=0.683\n",
            ">4, 20/234, d=0.739, g=0.680\n",
            ">4, 21/234, d=0.735, g=0.667\n",
            ">4, 22/234, d=0.742, g=0.658\n",
            ">4, 23/234, d=0.751, g=0.665\n",
            ">4, 24/234, d=0.735, g=0.678\n",
            ">4, 25/234, d=0.749, g=0.677\n",
            ">4, 26/234, d=0.748, g=0.683\n",
            ">4, 27/234, d=0.737, g=0.713\n",
            ">4, 28/234, d=0.740, g=0.695\n",
            ">4, 29/234, d=0.739, g=0.686\n",
            ">4, 30/234, d=0.720, g=0.706\n",
            ">4, 31/234, d=0.730, g=0.713\n",
            ">4, 32/234, d=0.735, g=0.700\n",
            ">4, 33/234, d=0.742, g=0.707\n",
            ">4, 34/234, d=0.715, g=0.706\n",
            ">4, 35/234, d=0.709, g=0.712\n",
            ">4, 36/234, d=0.717, g=0.710\n",
            ">4, 37/234, d=0.726, g=0.707\n",
            ">4, 38/234, d=0.722, g=0.696\n",
            ">4, 39/234, d=0.726, g=0.677\n",
            ">4, 40/234, d=0.723, g=0.685\n",
            ">4, 41/234, d=0.720, g=0.697\n",
            ">4, 42/234, d=0.719, g=0.688\n",
            ">4, 43/234, d=0.720, g=0.695\n",
            ">4, 44/234, d=0.717, g=0.708\n",
            ">4, 45/234, d=0.719, g=0.709\n",
            ">4, 46/234, d=0.710, g=0.712\n",
            ">4, 47/234, d=0.716, g=0.702\n",
            ">4, 48/234, d=0.713, g=0.713\n",
            ">4, 49/234, d=0.713, g=0.714\n",
            ">4, 50/234, d=0.707, g=0.705\n",
            ">4, 51/234, d=0.701, g=0.718\n",
            ">4, 52/234, d=0.694, g=0.729\n",
            ">4, 53/234, d=0.719, g=0.727\n",
            ">4, 54/234, d=0.688, g=0.743\n",
            ">4, 55/234, d=0.686, g=0.757\n",
            ">4, 56/234, d=0.683, g=0.771\n",
            ">4, 57/234, d=0.673, g=0.774\n",
            ">4, 58/234, d=0.664, g=0.805\n",
            ">4, 59/234, d=0.666, g=0.819\n",
            ">4, 60/234, d=0.654, g=0.816\n",
            ">4, 61/234, d=0.656, g=0.831\n",
            ">4, 62/234, d=0.636, g=0.814\n",
            ">4, 63/234, d=0.639, g=0.850\n",
            ">4, 64/234, d=0.628, g=0.854\n",
            ">4, 65/234, d=0.614, g=0.868\n",
            ">4, 66/234, d=0.614, g=0.866\n",
            ">4, 67/234, d=0.600, g=0.890\n",
            ">4, 68/234, d=0.624, g=0.890\n",
            ">4, 69/234, d=0.603, g=0.896\n",
            ">4, 70/234, d=0.603, g=0.912\n",
            ">4, 71/234, d=0.604, g=0.918\n",
            ">4, 72/234, d=0.613, g=0.935\n",
            ">4, 73/234, d=0.618, g=0.909\n",
            ">4, 74/234, d=0.599, g=0.896\n",
            ">4, 75/234, d=0.615, g=0.898\n",
            ">4, 76/234, d=0.622, g=0.889\n",
            ">4, 77/234, d=0.636, g=0.845\n",
            ">4, 78/234, d=0.622, g=0.827\n",
            ">4, 79/234, d=0.621, g=0.802\n",
            ">4, 80/234, d=0.633, g=0.778\n",
            ">4, 81/234, d=0.630, g=0.749\n",
            ">4, 82/234, d=0.650, g=0.744\n",
            ">4, 83/234, d=0.625, g=0.752\n",
            ">4, 84/234, d=0.648, g=0.730\n",
            ">4, 85/234, d=0.642, g=0.735\n",
            ">4, 86/234, d=0.652, g=0.733\n",
            ">4, 87/234, d=0.641, g=0.731\n",
            ">4, 88/234, d=0.645, g=0.763\n",
            ">4, 89/234, d=0.645, g=0.786\n",
            ">4, 90/234, d=0.653, g=0.794\n",
            ">4, 91/234, d=0.657, g=0.792\n",
            ">4, 92/234, d=0.657, g=0.770\n",
            ">4, 93/234, d=0.653, g=0.762\n",
            ">4, 94/234, d=0.651, g=0.749\n",
            ">4, 95/234, d=0.662, g=0.738\n",
            ">4, 96/234, d=0.664, g=0.722\n",
            ">4, 97/234, d=0.649, g=0.711\n",
            ">4, 98/234, d=0.677, g=0.689\n",
            ">4, 99/234, d=0.662, g=0.671\n",
            ">4, 100/234, d=0.666, g=0.687\n",
            ">4, 101/234, d=0.671, g=0.726\n",
            ">4, 102/234, d=0.694, g=0.738\n",
            ">4, 103/234, d=0.680, g=0.754\n",
            ">4, 104/234, d=0.685, g=0.760\n",
            ">4, 105/234, d=0.702, g=0.765\n",
            ">4, 106/234, d=0.698, g=0.755\n",
            ">4, 107/234, d=0.679, g=0.727\n",
            ">4, 108/234, d=0.694, g=0.693\n",
            ">4, 109/234, d=0.699, g=0.680\n",
            ">4, 110/234, d=0.697, g=0.648\n",
            ">4, 111/234, d=0.684, g=0.658\n",
            ">4, 112/234, d=0.703, g=0.638\n",
            ">4, 113/234, d=0.723, g=0.634\n",
            ">4, 114/234, d=0.728, g=0.665\n",
            ">4, 115/234, d=0.721, g=0.672\n",
            ">4, 116/234, d=0.729, g=0.700\n",
            ">4, 117/234, d=0.741, g=0.691\n",
            ">4, 118/234, d=0.746, g=0.676\n",
            ">4, 119/234, d=0.740, g=0.683\n",
            ">4, 120/234, d=0.761, g=0.662\n",
            ">4, 121/234, d=0.751, g=0.635\n",
            ">4, 122/234, d=0.765, g=0.632\n",
            ">4, 123/234, d=0.773, g=0.616\n",
            ">4, 124/234, d=0.783, g=0.633\n",
            ">4, 125/234, d=0.800, g=0.632\n",
            ">4, 126/234, d=0.777, g=0.653\n",
            ">4, 127/234, d=0.793, g=0.645\n",
            ">4, 128/234, d=0.787, g=0.648\n",
            ">4, 129/234, d=0.799, g=0.643\n",
            ">4, 130/234, d=0.807, g=0.651\n",
            ">4, 131/234, d=0.811, g=0.648\n",
            ">4, 132/234, d=0.820, g=0.662\n",
            ">4, 133/234, d=0.803, g=0.642\n",
            ">4, 134/234, d=0.796, g=0.630\n",
            ">4, 135/234, d=0.797, g=0.634\n",
            ">4, 136/234, d=0.782, g=0.640\n",
            ">4, 137/234, d=0.801, g=0.617\n",
            ">4, 138/234, d=0.791, g=0.641\n",
            ">4, 139/234, d=0.786, g=0.667\n",
            ">4, 140/234, d=0.766, g=0.681\n",
            ">4, 141/234, d=0.745, g=0.683\n",
            ">4, 142/234, d=0.755, g=0.708\n",
            ">4, 143/234, d=0.734, g=0.708\n",
            ">4, 144/234, d=0.734, g=0.717\n",
            ">4, 145/234, d=0.734, g=0.713\n",
            ">4, 146/234, d=0.707, g=0.717\n",
            ">4, 147/234, d=0.714, g=0.717\n",
            ">4, 148/234, d=0.709, g=0.735\n",
            ">4, 149/234, d=0.689, g=0.727\n",
            ">4, 150/234, d=0.677, g=0.743\n",
            ">4, 151/234, d=0.672, g=0.749\n",
            ">4, 152/234, d=0.671, g=0.752\n",
            ">4, 153/234, d=0.660, g=0.744\n",
            ">4, 154/234, d=0.655, g=0.747\n",
            ">4, 155/234, d=0.649, g=0.770\n",
            ">4, 156/234, d=0.648, g=0.765\n",
            ">4, 157/234, d=0.653, g=0.780\n",
            ">4, 158/234, d=0.627, g=0.775\n",
            ">4, 159/234, d=0.624, g=0.786\n",
            ">4, 160/234, d=0.634, g=0.790\n",
            ">4, 161/234, d=0.636, g=0.812\n",
            ">4, 162/234, d=0.611, g=0.806\n",
            ">4, 163/234, d=0.624, g=0.788\n",
            ">4, 164/234, d=0.628, g=0.791\n",
            ">4, 165/234, d=0.620, g=0.804\n",
            ">4, 166/234, d=0.633, g=0.790\n",
            ">4, 167/234, d=0.623, g=0.807\n",
            ">4, 168/234, d=0.619, g=0.804\n",
            ">4, 169/234, d=0.635, g=0.827\n",
            ">4, 170/234, d=0.637, g=0.830\n",
            ">4, 171/234, d=0.627, g=0.838\n",
            ">4, 172/234, d=0.627, g=0.824\n",
            ">4, 173/234, d=0.643, g=0.829\n",
            ">4, 174/234, d=0.645, g=0.815\n",
            ">4, 175/234, d=0.644, g=0.789\n",
            ">4, 176/234, d=0.649, g=0.782\n",
            ">4, 177/234, d=0.648, g=0.774\n",
            ">4, 178/234, d=0.655, g=0.760\n",
            ">4, 179/234, d=0.651, g=0.754\n",
            ">4, 180/234, d=0.658, g=0.739\n",
            ">4, 181/234, d=0.654, g=0.732\n",
            ">4, 182/234, d=0.668, g=0.739\n",
            ">4, 183/234, d=0.660, g=0.714\n",
            ">4, 184/234, d=0.668, g=0.728\n",
            ">4, 185/234, d=0.656, g=0.737\n",
            ">4, 186/234, d=0.653, g=0.734\n",
            ">4, 187/234, d=0.661, g=0.722\n",
            ">4, 188/234, d=0.677, g=0.707\n",
            ">4, 189/234, d=0.676, g=0.721\n",
            ">4, 190/234, d=0.662, g=0.697\n",
            ">4, 191/234, d=0.670, g=0.705\n",
            ">4, 192/234, d=0.672, g=0.690\n",
            ">4, 193/234, d=0.672, g=0.700\n",
            ">4, 194/234, d=0.676, g=0.711\n",
            ">4, 195/234, d=0.684, g=0.713\n",
            ">4, 196/234, d=0.675, g=0.725\n",
            ">4, 197/234, d=0.681, g=0.703\n",
            ">4, 198/234, d=0.697, g=0.721\n",
            ">4, 199/234, d=0.692, g=0.694\n",
            ">4, 200/234, d=0.685, g=0.704\n",
            ">4, 201/234, d=0.696, g=0.696\n",
            ">4, 202/234, d=0.715, g=0.689\n",
            ">4, 203/234, d=0.702, g=0.674\n",
            ">4, 204/234, d=0.705, g=0.688\n",
            ">4, 205/234, d=0.689, g=0.686\n",
            ">4, 206/234, d=0.704, g=0.690\n",
            ">4, 207/234, d=0.685, g=0.692\n",
            ">4, 208/234, d=0.694, g=0.700\n",
            ">4, 209/234, d=0.698, g=0.715\n",
            ">4, 210/234, d=0.691, g=0.720\n",
            ">4, 211/234, d=0.715, g=0.708\n",
            ">4, 212/234, d=0.705, g=0.718\n",
            ">4, 213/234, d=0.711, g=0.721\n",
            ">4, 214/234, d=0.702, g=0.717\n",
            ">4, 215/234, d=0.709, g=0.706\n",
            ">4, 216/234, d=0.706, g=0.685\n",
            ">4, 217/234, d=0.703, g=0.677\n",
            ">4, 218/234, d=0.711, g=0.670\n",
            ">4, 219/234, d=0.701, g=0.681\n",
            ">4, 220/234, d=0.712, g=0.691\n",
            ">4, 221/234, d=0.715, g=0.700\n",
            ">4, 222/234, d=0.706, g=0.695\n",
            ">4, 223/234, d=0.702, g=0.716\n",
            ">4, 224/234, d=0.721, g=0.726\n",
            ">4, 225/234, d=0.690, g=0.712\n",
            ">4, 226/234, d=0.710, g=0.737\n",
            ">4, 227/234, d=0.701, g=0.733\n",
            ">4, 228/234, d=0.694, g=0.732\n",
            ">4, 229/234, d=0.710, g=0.715\n",
            ">4, 230/234, d=0.686, g=0.710\n",
            ">4, 231/234, d=0.706, g=0.707\n",
            ">4, 232/234, d=0.695, g=0.716\n",
            ">4, 233/234, d=0.705, g=0.700\n",
            ">4, 234/234, d=0.696, g=0.718\n",
            ">5, 1/234, d=0.702, g=0.707\n",
            ">5, 2/234, d=0.689, g=0.703\n",
            ">5, 3/234, d=0.687, g=0.702\n",
            ">5, 4/234, d=0.694, g=0.704\n",
            ">5, 5/234, d=0.685, g=0.702\n",
            ">5, 6/234, d=0.699, g=0.713\n",
            ">5, 7/234, d=0.699, g=0.723\n",
            ">5, 8/234, d=0.674, g=0.730\n",
            ">5, 9/234, d=0.689, g=0.728\n",
            ">5, 10/234, d=0.692, g=0.729\n",
            ">5, 11/234, d=0.696, g=0.712\n",
            ">5, 12/234, d=0.693, g=0.715\n",
            ">5, 13/234, d=0.703, g=0.716\n",
            ">5, 14/234, d=0.700, g=0.711\n",
            ">5, 15/234, d=0.695, g=0.701\n",
            ">5, 16/234, d=0.697, g=0.696\n",
            ">5, 17/234, d=0.700, g=0.684\n",
            ">5, 18/234, d=0.697, g=0.701\n",
            ">5, 19/234, d=0.692, g=0.710\n",
            ">5, 20/234, d=0.697, g=0.725\n",
            ">5, 21/234, d=0.695, g=0.720\n",
            ">5, 22/234, d=0.699, g=0.734\n",
            ">5, 23/234, d=0.691, g=0.731\n",
            ">5, 24/234, d=0.699, g=0.723\n",
            ">5, 25/234, d=0.697, g=0.717\n",
            ">5, 26/234, d=0.687, g=0.719\n",
            ">5, 27/234, d=0.685, g=0.709\n",
            ">5, 28/234, d=0.702, g=0.708\n",
            ">5, 29/234, d=0.695, g=0.709\n",
            ">5, 30/234, d=0.704, g=0.708\n",
            ">5, 31/234, d=0.705, g=0.705\n",
            ">5, 32/234, d=0.685, g=0.714\n",
            ">5, 33/234, d=0.702, g=0.714\n",
            ">5, 34/234, d=0.701, g=0.722\n",
            ">5, 35/234, d=0.702, g=0.711\n",
            ">5, 36/234, d=0.683, g=0.731\n",
            ">5, 37/234, d=0.697, g=0.707\n",
            ">5, 38/234, d=0.706, g=0.720\n",
            ">5, 39/234, d=0.694, g=0.733\n",
            ">5, 40/234, d=0.695, g=0.719\n",
            ">5, 41/234, d=0.700, g=0.721\n",
            ">5, 42/234, d=0.687, g=0.719\n",
            ">5, 43/234, d=0.692, g=0.722\n",
            ">5, 44/234, d=0.697, g=0.728\n",
            ">5, 45/234, d=0.695, g=0.722\n",
            ">5, 46/234, d=0.700, g=0.729\n",
            ">5, 47/234, d=0.691, g=0.730\n",
            ">5, 48/234, d=0.690, g=0.724\n",
            ">5, 49/234, d=0.694, g=0.724\n",
            ">5, 50/234, d=0.672, g=0.718\n",
            ">5, 51/234, d=0.688, g=0.732\n",
            ">5, 52/234, d=0.684, g=0.742\n",
            ">5, 53/234, d=0.681, g=0.731\n",
            ">5, 54/234, d=0.678, g=0.729\n",
            ">5, 55/234, d=0.685, g=0.746\n",
            ">5, 56/234, d=0.677, g=0.731\n",
            ">5, 57/234, d=0.687, g=0.734\n",
            ">5, 58/234, d=0.688, g=0.749\n",
            ">5, 59/234, d=0.689, g=0.736\n",
            ">5, 60/234, d=0.673, g=0.740\n",
            ">5, 61/234, d=0.674, g=0.742\n",
            ">5, 62/234, d=0.670, g=0.752\n",
            ">5, 63/234, d=0.678, g=0.766\n",
            ">5, 64/234, d=0.673, g=0.750\n",
            ">5, 65/234, d=0.676, g=0.763\n",
            ">5, 66/234, d=0.669, g=0.738\n",
            ">5, 67/234, d=0.665, g=0.758\n",
            ">5, 68/234, d=0.675, g=0.756\n",
            ">5, 69/234, d=0.673, g=0.740\n",
            ">5, 70/234, d=0.659, g=0.742\n",
            ">5, 71/234, d=0.667, g=0.746\n",
            ">5, 72/234, d=0.668, g=0.736\n",
            ">5, 73/234, d=0.670, g=0.749\n",
            ">5, 74/234, d=0.663, g=0.737\n",
            ">5, 75/234, d=0.665, g=0.743\n",
            ">5, 76/234, d=0.674, g=0.752\n",
            ">5, 77/234, d=0.665, g=0.750\n",
            ">5, 78/234, d=0.666, g=0.754\n",
            ">5, 79/234, d=0.668, g=0.765\n",
            ">5, 80/234, d=0.681, g=0.767\n",
            ">5, 81/234, d=0.667, g=0.786\n",
            ">5, 82/234, d=0.655, g=0.764\n",
            ">5, 83/234, d=0.662, g=0.754\n",
            ">5, 84/234, d=0.677, g=0.751\n",
            ">5, 85/234, d=0.661, g=0.745\n",
            ">5, 86/234, d=0.666, g=0.736\n",
            ">5, 87/234, d=0.664, g=0.726\n",
            ">5, 88/234, d=0.662, g=0.739\n",
            ">5, 89/234, d=0.664, g=0.729\n",
            ">5, 90/234, d=0.672, g=0.730\n",
            ">5, 91/234, d=0.657, g=0.742\n",
            ">5, 92/234, d=0.661, g=0.732\n",
            ">5, 93/234, d=0.663, g=0.735\n",
            ">5, 94/234, d=0.663, g=0.745\n",
            ">5, 95/234, d=0.680, g=0.764\n",
            ">5, 96/234, d=0.674, g=0.747\n",
            ">5, 97/234, d=0.663, g=0.754\n",
            ">5, 98/234, d=0.676, g=0.747\n",
            ">5, 99/234, d=0.671, g=0.734\n",
            ">5, 100/234, d=0.674, g=0.733\n",
            ">5, 101/234, d=0.666, g=0.736\n",
            ">5, 102/234, d=0.663, g=0.723\n",
            ">5, 103/234, d=0.677, g=0.724\n",
            ">5, 104/234, d=0.675, g=0.734\n",
            ">5, 105/234, d=0.683, g=0.733\n",
            ">5, 106/234, d=0.689, g=0.728\n",
            ">5, 107/234, d=0.678, g=0.739\n",
            ">5, 108/234, d=0.674, g=0.751\n",
            ">5, 109/234, d=0.654, g=0.750\n",
            ">5, 110/234, d=0.668, g=0.736\n",
            ">5, 111/234, d=0.658, g=0.732\n",
            ">5, 112/234, d=0.667, g=0.725\n",
            ">5, 113/234, d=0.674, g=0.725\n",
            ">5, 114/234, d=0.671, g=0.724\n",
            ">5, 115/234, d=0.673, g=0.719\n",
            ">5, 116/234, d=0.681, g=0.730\n",
            ">5, 117/234, d=0.665, g=0.732\n",
            ">5, 118/234, d=0.679, g=0.731\n",
            ">5, 119/234, d=0.671, g=0.754\n",
            ">5, 120/234, d=0.676, g=0.742\n",
            ">5, 121/234, d=0.669, g=0.730\n",
            ">5, 122/234, d=0.659, g=0.739\n",
            ">5, 123/234, d=0.682, g=0.746\n",
            ">5, 124/234, d=0.672, g=0.721\n",
            ">5, 125/234, d=0.700, g=0.723\n",
            ">5, 126/234, d=0.686, g=0.726\n",
            ">5, 127/234, d=0.684, g=0.736\n",
            ">5, 128/234, d=0.687, g=0.727\n",
            ">5, 129/234, d=0.674, g=0.715\n",
            ">5, 130/234, d=0.691, g=0.727\n",
            ">5, 131/234, d=0.667, g=0.715\n",
            ">5, 132/234, d=0.663, g=0.729\n",
            ">5, 133/234, d=0.676, g=0.721\n",
            ">5, 134/234, d=0.692, g=0.712\n",
            ">5, 135/234, d=0.672, g=0.728\n",
            ">5, 136/234, d=0.678, g=0.734\n",
            ">5, 137/234, d=0.676, g=0.715\n",
            ">5, 138/234, d=0.685, g=0.740\n",
            ">5, 139/234, d=0.678, g=0.720\n",
            ">5, 140/234, d=0.704, g=0.733\n",
            ">5, 141/234, d=0.685, g=0.726\n",
            ">5, 142/234, d=0.707, g=0.745\n",
            ">5, 143/234, d=0.697, g=0.727\n",
            ">5, 144/234, d=0.685, g=0.736\n",
            ">5, 145/234, d=0.684, g=0.716\n",
            ">5, 146/234, d=0.708, g=0.704\n",
            ">5, 147/234, d=0.704, g=0.703\n",
            ">5, 148/234, d=0.697, g=0.702\n",
            ">5, 149/234, d=0.694, g=0.697\n",
            ">5, 150/234, d=0.696, g=0.703\n",
            ">5, 151/234, d=0.711, g=0.716\n",
            ">5, 152/234, d=0.704, g=0.703\n",
            ">5, 153/234, d=0.700, g=0.719\n",
            ">5, 154/234, d=0.705, g=0.701\n",
            ">5, 155/234, d=0.707, g=0.694\n",
            ">5, 156/234, d=0.710, g=0.703\n",
            ">5, 157/234, d=0.703, g=0.704\n",
            ">5, 158/234, d=0.716, g=0.714\n",
            ">5, 159/234, d=0.713, g=0.722\n",
            ">5, 160/234, d=0.708, g=0.704\n",
            ">5, 161/234, d=0.698, g=0.716\n",
            ">5, 162/234, d=0.704, g=0.702\n",
            ">5, 163/234, d=0.704, g=0.702\n",
            ">5, 164/234, d=0.707, g=0.720\n",
            ">5, 165/234, d=0.700, g=0.704\n",
            ">5, 166/234, d=0.706, g=0.711\n",
            ">5, 167/234, d=0.711, g=0.711\n",
            ">5, 168/234, d=0.714, g=0.704\n",
            ">5, 169/234, d=0.700, g=0.705\n",
            ">5, 170/234, d=0.722, g=0.706\n",
            ">5, 171/234, d=0.694, g=0.717\n",
            ">5, 172/234, d=0.694, g=0.710\n",
            ">5, 173/234, d=0.695, g=0.710\n",
            ">5, 174/234, d=0.699, g=0.710\n",
            ">5, 175/234, d=0.701, g=0.722\n",
            ">5, 176/234, d=0.686, g=0.717\n",
            ">5, 177/234, d=0.695, g=0.709\n",
            ">5, 178/234, d=0.692, g=0.700\n",
            ">5, 179/234, d=0.694, g=0.723\n",
            ">5, 180/234, d=0.693, g=0.699\n",
            ">5, 181/234, d=0.698, g=0.713\n",
            ">5, 182/234, d=0.702, g=0.707\n",
            ">5, 183/234, d=0.682, g=0.727\n",
            ">5, 184/234, d=0.694, g=0.730\n",
            ">5, 185/234, d=0.690, g=0.735\n",
            ">5, 186/234, d=0.696, g=0.716\n",
            ">5, 187/234, d=0.683, g=0.740\n",
            ">5, 188/234, d=0.690, g=0.742\n",
            ">5, 189/234, d=0.686, g=0.732\n",
            ">5, 190/234, d=0.678, g=0.730\n",
            ">5, 191/234, d=0.677, g=0.713\n",
            ">5, 192/234, d=0.687, g=0.708\n",
            ">5, 193/234, d=0.682, g=0.739\n",
            ">5, 194/234, d=0.682, g=0.726\n",
            ">5, 195/234, d=0.681, g=0.727\n",
            ">5, 196/234, d=0.681, g=0.736\n",
            ">5, 197/234, d=0.679, g=0.735\n",
            ">5, 198/234, d=0.682, g=0.733\n",
            ">5, 199/234, d=0.672, g=0.731\n",
            ">5, 200/234, d=0.671, g=0.731\n",
            ">5, 201/234, d=0.677, g=0.741\n",
            ">5, 202/234, d=0.682, g=0.743\n",
            ">5, 203/234, d=0.677, g=0.749\n",
            ">5, 204/234, d=0.668, g=0.742\n",
            ">5, 205/234, d=0.674, g=0.741\n",
            ">5, 206/234, d=0.679, g=0.747\n",
            ">5, 207/234, d=0.674, g=0.736\n",
            ">5, 208/234, d=0.679, g=0.735\n",
            ">5, 209/234, d=0.659, g=0.711\n",
            ">5, 210/234, d=0.672, g=0.727\n",
            ">5, 211/234, d=0.676, g=0.742\n",
            ">5, 212/234, d=0.674, g=0.733\n",
            ">5, 213/234, d=0.676, g=0.752\n",
            ">5, 214/234, d=0.666, g=0.763\n",
            ">5, 215/234, d=0.662, g=0.749\n",
            ">5, 216/234, d=0.665, g=0.748\n",
            ">5, 217/234, d=0.657, g=0.749\n",
            ">5, 218/234, d=0.660, g=0.739\n",
            ">5, 219/234, d=0.663, g=0.734\n",
            ">5, 220/234, d=0.669, g=0.740\n",
            ">5, 221/234, d=0.664, g=0.746\n",
            ">5, 222/234, d=0.663, g=0.731\n",
            ">5, 223/234, d=0.671, g=0.751\n",
            ">5, 224/234, d=0.676, g=0.743\n",
            ">5, 225/234, d=0.673, g=0.751\n",
            ">5, 226/234, d=0.673, g=0.732\n",
            ">5, 227/234, d=0.664, g=0.727\n",
            ">5, 228/234, d=0.677, g=0.726\n",
            ">5, 229/234, d=0.672, g=0.731\n",
            ">5, 230/234, d=0.675, g=0.728\n",
            ">5, 231/234, d=0.676, g=0.734\n",
            ">5, 232/234, d=0.664, g=0.751\n",
            ">5, 233/234, d=0.670, g=0.744\n",
            ">5, 234/234, d=0.666, g=0.741\n",
            ">6, 1/234, d=0.672, g=0.732\n",
            ">6, 2/234, d=0.685, g=0.731\n",
            ">6, 3/234, d=0.679, g=0.730\n",
            ">6, 4/234, d=0.676, g=0.734\n",
            ">6, 5/234, d=0.679, g=0.713\n",
            ">6, 6/234, d=0.688, g=0.710\n",
            ">6, 7/234, d=0.675, g=0.695\n",
            ">6, 8/234, d=0.676, g=0.688\n",
            ">6, 9/234, d=0.678, g=0.694\n",
            ">6, 10/234, d=0.692, g=0.687\n",
            ">6, 11/234, d=0.677, g=0.738\n",
            ">6, 12/234, d=0.693, g=0.721\n",
            ">6, 13/234, d=0.696, g=0.731\n",
            ">6, 14/234, d=0.691, g=0.734\n",
            ">6, 15/234, d=0.696, g=0.747\n",
            ">6, 16/234, d=0.691, g=0.725\n",
            ">6, 17/234, d=0.700, g=0.718\n",
            ">6, 18/234, d=0.697, g=0.701\n",
            ">6, 19/234, d=0.701, g=0.699\n",
            ">6, 20/234, d=0.692, g=0.697\n",
            ">6, 21/234, d=0.691, g=0.701\n",
            ">6, 22/234, d=0.688, g=0.687\n",
            ">6, 23/234, d=0.693, g=0.700\n",
            ">6, 24/234, d=0.688, g=0.699\n",
            ">6, 25/234, d=0.699, g=0.701\n",
            ">6, 26/234, d=0.694, g=0.720\n",
            ">6, 27/234, d=0.710, g=0.717\n",
            ">6, 28/234, d=0.689, g=0.703\n",
            ">6, 29/234, d=0.692, g=0.710\n",
            ">6, 30/234, d=0.693, g=0.714\n",
            ">6, 31/234, d=0.693, g=0.710\n",
            ">6, 32/234, d=0.695, g=0.712\n",
            ">6, 33/234, d=0.694, g=0.705\n",
            ">6, 34/234, d=0.701, g=0.716\n",
            ">6, 35/234, d=0.692, g=0.710\n",
            ">6, 36/234, d=0.686, g=0.711\n",
            ">6, 37/234, d=0.691, g=0.702\n",
            ">6, 38/234, d=0.694, g=0.706\n",
            ">6, 39/234, d=0.691, g=0.710\n",
            ">6, 40/234, d=0.682, g=0.701\n",
            ">6, 41/234, d=0.701, g=0.708\n",
            ">6, 42/234, d=0.683, g=0.705\n",
            ">6, 43/234, d=0.691, g=0.725\n",
            ">6, 44/234, d=0.698, g=0.710\n",
            ">6, 45/234, d=0.681, g=0.713\n",
            ">6, 46/234, d=0.693, g=0.728\n",
            ">6, 47/234, d=0.696, g=0.718\n",
            ">6, 48/234, d=0.688, g=0.710\n",
            ">6, 49/234, d=0.697, g=0.713\n",
            ">6, 50/234, d=0.691, g=0.702\n",
            ">6, 51/234, d=0.687, g=0.703\n",
            ">6, 52/234, d=0.679, g=0.702\n",
            ">6, 53/234, d=0.691, g=0.711\n",
            ">6, 54/234, d=0.680, g=0.720\n",
            ">6, 55/234, d=0.689, g=0.717\n",
            ">6, 56/234, d=0.692, g=0.730\n",
            ">6, 57/234, d=0.684, g=0.749\n",
            ">6, 58/234, d=0.678, g=0.739\n",
            ">6, 59/234, d=0.685, g=0.732\n",
            ">6, 60/234, d=0.696, g=0.724\n",
            ">6, 61/234, d=0.686, g=0.725\n",
            ">6, 62/234, d=0.675, g=0.707\n",
            ">6, 63/234, d=0.675, g=0.705\n",
            ">6, 64/234, d=0.692, g=0.712\n",
            ">6, 65/234, d=0.699, g=0.706\n",
            ">6, 66/234, d=0.685, g=0.700\n",
            ">6, 67/234, d=0.692, g=0.714\n",
            ">6, 68/234, d=0.678, g=0.714\n",
            ">6, 69/234, d=0.681, g=0.727\n",
            ">6, 70/234, d=0.673, g=0.739\n",
            ">6, 71/234, d=0.685, g=0.749\n",
            ">6, 72/234, d=0.676, g=0.752\n",
            ">6, 73/234, d=0.679, g=0.749\n",
            ">6, 74/234, d=0.682, g=0.729\n",
            ">6, 75/234, d=0.682, g=0.721\n",
            ">6, 76/234, d=0.679, g=0.727\n",
            ">6, 77/234, d=0.676, g=0.709\n",
            ">6, 78/234, d=0.691, g=0.706\n",
            ">6, 79/234, d=0.672, g=0.694\n",
            ">6, 80/234, d=0.683, g=0.703\n",
            ">6, 81/234, d=0.688, g=0.711\n",
            ">6, 82/234, d=0.679, g=0.725\n",
            ">6, 83/234, d=0.686, g=0.731\n",
            ">6, 84/234, d=0.679, g=0.734\n",
            ">6, 85/234, d=0.691, g=0.747\n",
            ">6, 86/234, d=0.691, g=0.753\n",
            ">6, 87/234, d=0.672, g=0.743\n",
            ">6, 88/234, d=0.683, g=0.753\n",
            ">6, 89/234, d=0.675, g=0.726\n",
            ">6, 90/234, d=0.688, g=0.729\n",
            ">6, 91/234, d=0.681, g=0.722\n",
            ">6, 92/234, d=0.666, g=0.722\n",
            ">6, 93/234, d=0.683, g=0.704\n",
            ">6, 94/234, d=0.684, g=0.712\n",
            ">6, 95/234, d=0.680, g=0.722\n",
            ">6, 96/234, d=0.688, g=0.719\n",
            ">6, 97/234, d=0.681, g=0.739\n",
            ">6, 98/234, d=0.674, g=0.734\n",
            ">6, 99/234, d=0.686, g=0.741\n",
            ">6, 100/234, d=0.668, g=0.740\n",
            ">6, 101/234, d=0.693, g=0.730\n",
            ">6, 102/234, d=0.688, g=0.738\n",
            ">6, 103/234, d=0.673, g=0.731\n",
            ">6, 104/234, d=0.684, g=0.713\n",
            ">6, 105/234, d=0.690, g=0.705\n",
            ">6, 106/234, d=0.693, g=0.704\n",
            ">6, 107/234, d=0.680, g=0.692\n",
            ">6, 108/234, d=0.687, g=0.698\n",
            ">6, 109/234, d=0.696, g=0.703\n",
            ">6, 110/234, d=0.691, g=0.696\n",
            ">6, 111/234, d=0.693, g=0.711\n",
            ">6, 112/234, d=0.700, g=0.707\n",
            ">6, 113/234, d=0.698, g=0.717\n",
            ">6, 114/234, d=0.694, g=0.718\n",
            ">6, 115/234, d=0.693, g=0.723\n",
            ">6, 116/234, d=0.698, g=0.718\n",
            ">6, 117/234, d=0.702, g=0.700\n",
            ">6, 118/234, d=0.686, g=0.702\n",
            ">6, 119/234, d=0.698, g=0.695\n",
            ">6, 120/234, d=0.704, g=0.686\n",
            ">6, 121/234, d=0.695, g=0.680\n",
            ">6, 122/234, d=0.720, g=0.680\n",
            ">6, 123/234, d=0.707, g=0.690\n",
            ">6, 124/234, d=0.709, g=0.693\n",
            ">6, 125/234, d=0.701, g=0.694\n",
            ">6, 126/234, d=0.703, g=0.702\n",
            ">6, 127/234, d=0.696, g=0.705\n",
            ">6, 128/234, d=0.707, g=0.715\n",
            ">6, 129/234, d=0.711, g=0.698\n",
            ">6, 130/234, d=0.711, g=0.706\n",
            ">6, 131/234, d=0.707, g=0.691\n",
            ">6, 132/234, d=0.706, g=0.687\n",
            ">6, 133/234, d=0.708, g=0.688\n",
            ">6, 134/234, d=0.698, g=0.686\n",
            ">6, 135/234, d=0.697, g=0.695\n",
            ">6, 136/234, d=0.714, g=0.692\n",
            ">6, 137/234, d=0.701, g=0.709\n",
            ">6, 138/234, d=0.712, g=0.695\n",
            ">6, 139/234, d=0.706, g=0.705\n",
            ">6, 140/234, d=0.694, g=0.726\n",
            ">6, 141/234, d=0.693, g=0.719\n",
            ">6, 142/234, d=0.694, g=0.722\n",
            ">6, 143/234, d=0.684, g=0.713\n",
            ">6, 144/234, d=0.690, g=0.704\n",
            ">6, 145/234, d=0.702, g=0.701\n",
            ">6, 146/234, d=0.697, g=0.690\n",
            ">6, 147/234, d=0.687, g=0.687\n",
            ">6, 148/234, d=0.684, g=0.700\n",
            ">6, 149/234, d=0.696, g=0.700\n",
            ">6, 150/234, d=0.683, g=0.711\n",
            ">6, 151/234, d=0.680, g=0.719\n",
            ">6, 152/234, d=0.690, g=0.736\n",
            ">6, 153/234, d=0.680, g=0.744\n",
            ">6, 154/234, d=0.678, g=0.739\n",
            ">6, 155/234, d=0.683, g=0.740\n",
            ">6, 156/234, d=0.682, g=0.734\n",
            ">6, 157/234, d=0.680, g=0.733\n",
            ">6, 158/234, d=0.671, g=0.719\n",
            ">6, 159/234, d=0.674, g=0.711\n",
            ">6, 160/234, d=0.681, g=0.703\n",
            ">6, 161/234, d=0.675, g=0.702\n",
            ">6, 162/234, d=0.666, g=0.700\n",
            ">6, 163/234, d=0.672, g=0.708\n",
            ">6, 164/234, d=0.671, g=0.702\n",
            ">6, 165/234, d=0.675, g=0.706\n",
            ">6, 166/234, d=0.681, g=0.735\n",
            ">6, 167/234, d=0.673, g=0.761\n",
            ">6, 168/234, d=0.677, g=0.774\n",
            ">6, 169/234, d=0.680, g=0.765\n",
            ">6, 170/234, d=0.676, g=0.771\n",
            ">6, 171/234, d=0.684, g=0.754\n",
            ">6, 172/234, d=0.676, g=0.720\n",
            ">6, 173/234, d=0.676, g=0.701\n",
            ">6, 174/234, d=0.681, g=0.688\n",
            ">6, 175/234, d=0.682, g=0.676\n",
            ">6, 176/234, d=0.684, g=0.654\n",
            ">6, 177/234, d=0.681, g=0.654\n",
            ">6, 178/234, d=0.679, g=0.669\n",
            ">6, 179/234, d=0.684, g=0.695\n",
            ">6, 180/234, d=0.689, g=0.728\n",
            ">6, 181/234, d=0.696, g=0.756\n",
            ">6, 182/234, d=0.684, g=0.784\n",
            ">6, 183/234, d=0.691, g=0.780\n",
            ">6, 184/234, d=0.700, g=0.747\n",
            ">6, 185/234, d=0.701, g=0.714\n",
            ">6, 186/234, d=0.694, g=0.694\n",
            ">6, 187/234, d=0.689, g=0.678\n",
            ">6, 188/234, d=0.690, g=0.667\n",
            ">6, 189/234, d=0.684, g=0.652\n",
            ">6, 190/234, d=0.696, g=0.643\n",
            ">6, 191/234, d=0.707, g=0.635\n",
            ">6, 192/234, d=0.701, g=0.656\n",
            ">6, 193/234, d=0.708, g=0.706\n",
            ">6, 194/234, d=0.708, g=0.753\n",
            ">6, 195/234, d=0.710, g=0.789\n",
            ">6, 196/234, d=0.699, g=0.795\n",
            ">6, 197/234, d=0.704, g=0.778\n",
            ">6, 198/234, d=0.709, g=0.731\n",
            ">6, 199/234, d=0.707, g=0.707\n",
            ">6, 200/234, d=0.715, g=0.686\n",
            ">6, 201/234, d=0.707, g=0.655\n",
            ">6, 202/234, d=0.687, g=0.650\n",
            ">6, 203/234, d=0.710, g=0.641\n",
            ">6, 204/234, d=0.713, g=0.627\n",
            ">6, 205/234, d=0.720, g=0.653\n",
            ">6, 206/234, d=0.712, g=0.693\n",
            ">6, 207/234, d=0.713, g=0.750\n",
            ">6, 208/234, d=0.708, g=0.797\n",
            ">6, 209/234, d=0.695, g=0.803\n",
            ">6, 210/234, d=0.707, g=0.783\n",
            ">6, 211/234, d=0.712, g=0.746\n",
            ">6, 212/234, d=0.704, g=0.733\n",
            ">6, 213/234, d=0.702, g=0.703\n",
            ">6, 214/234, d=0.697, g=0.682\n",
            ">6, 215/234, d=0.691, g=0.660\n",
            ">6, 216/234, d=0.688, g=0.651\n",
            ">6, 217/234, d=0.699, g=0.642\n",
            ">6, 218/234, d=0.695, g=0.649\n",
            ">6, 219/234, d=0.704, g=0.682\n",
            ">6, 220/234, d=0.700, g=0.720\n",
            ">6, 221/234, d=0.699, g=0.787\n",
            ">6, 222/234, d=0.668, g=0.846\n",
            ">6, 223/234, d=0.676, g=0.866\n",
            ">6, 224/234, d=0.684, g=0.824\n",
            ">6, 225/234, d=0.692, g=0.801\n",
            ">6, 226/234, d=0.693, g=0.750\n",
            ">6, 227/234, d=0.688, g=0.718\n",
            ">6, 228/234, d=0.680, g=0.693\n",
            ">6, 229/234, d=0.675, g=0.679\n",
            ">6, 230/234, d=0.660, g=0.666\n",
            ">6, 231/234, d=0.665, g=0.646\n",
            ">6, 232/234, d=0.676, g=0.628\n",
            ">6, 233/234, d=0.694, g=0.603\n",
            ">6, 234/234, d=0.705, g=0.626\n",
            ">7, 1/234, d=0.705, g=0.698\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-00216cf216cd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_real_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# train model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgan_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlatent_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-11-22c89103c64a>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(g_model, d_model, gan_model, dataset, latent_dim, n_epochs, n_batch)\u001b[0m\n\u001b[1;32m     19\u001b[0m                         \u001b[0my_gan\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m                         \u001b[0;31m# update the generator via the discriminator's error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m                         \u001b[0mg_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgan_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_gan\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_gan\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m                         \u001b[0;31m# summarize loss on this batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m                         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'>%d, %d/%d, d=%.3f, g=%.3f'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbat_per_epo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1447\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1448\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1449\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1450\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1451\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2977\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2979\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2980\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2981\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2935\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2936\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2937\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2938\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2939\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eGJTyiXN2_VE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        },
        "outputId": "922fca6a-fd3c-486f-e163-07ca218f9688"
      },
      "source": [
        "# example of generating an image for a specific point in the latent space\n",
        "from keras.models import load_model\n",
        "from numpy import asarray\n",
        "from matplotlib import pyplot\n",
        "# load model\n",
        "model = load_model('generator_model_6.h5')\n",
        "# all 0s\n",
        "vector = asarray([[0.0 for _ in range(100)]])\n",
        "# generate image\n",
        "X = model.predict(vector)\n",
        "# plot the result\n",
        "pyplot.imshow(X[0, :, :, 0], cmap='gray_r')\n",
        "pyplot.show()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-010ede37d8c7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpyplot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# load model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'generator_model_6.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;31m# all 0s\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mvector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.0\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py\u001b[0m in \u001b[0;36mload_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    456\u001b[0m                 \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp_filepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 458\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mload_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mload_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[1;32m    547\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mH5Dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_supported_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mH5Dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mh5dict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    550\u001b[0m             \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_deserialize_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh5dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'write'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/utils/io_utils.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path, mode)\u001b[0m\n\u001b[1;32m    189\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_is_path_instance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, **kwds)\u001b[0m\n\u001b[1;32m    310\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mphil\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m                 \u001b[0mfapl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_fapl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdriver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlibver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 312\u001b[0;31m                 \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_fid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muserblock_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mswmr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mswmr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mswmr\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m             \u001b[0mflags\u001b[0m \u001b[0;34m|=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_SWMR_READ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r+'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_RDWR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mh5py/h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.open\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: Unable to open file (unable to open file: name = 'generator_model_6.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)"
          ]
        }
      ]
    }
  ]
}